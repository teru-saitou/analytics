{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGQNQQszq-Rp",
        "outputId": "17e3e9f7-d305-4866-8a38-791435e5685a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.9/dist-packages (from pytorch-tabnet) (1.2.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.9/dist-packages (from pytorch-tabnet) (1.10.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.9/dist-packages (from pytorch-tabnet) (1.22.4)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.9/dist-packages (from pytorch-tabnet) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.9/dist-packages (from pytorch-tabnet) (4.65.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (4.5.0)\n",
            "Installing collected packages: pytorch-tabnet\n",
            "Successfully installed pytorch-tabnet-4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-tabnet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "HGfJQxQ3AmMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install japanize-matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQKVF--iAscj",
        "outputId": "91ccea40-4b1c-4b77-c54e-95ec52750fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting japanize-matplotlib\n",
            "  Downloading japanize-matplotlib-1.1.3.tar.gz (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from japanize-matplotlib) (3.5.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize-matplotlib) (23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize-matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize-matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize-matplotlib) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize-matplotlib) (1.22.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize-matplotlib) (4.39.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize-matplotlib) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize-matplotlib) (8.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->japanize-matplotlib) (1.15.0)\n",
            "Building wheels for collected packages: japanize-matplotlib\n",
            "  Building wheel for japanize-matplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for japanize-matplotlib: filename=japanize_matplotlib-1.1.3-py3-none-any.whl size=4120275 sha256=944ef9ebe0a346d283b441b601dfcb0c1fa2f0b64b1b2212605d84ff7315e004\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/8f/c2/83055ad0c9591b0a094730aa7cb2cc12fedacbcd2241baf534\n",
            "Successfully built japanize-matplotlib\n",
            "Installing collected packages: japanize-matplotlib\n",
            "Successfully installed japanize-matplotlib-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import japanize_matplotlib"
      ],
      "metadata": {
        "id": "Xj7l4tPXAvcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rP_XPTJynrIT"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"mid.csv\",encoding ='UTF-8')\n",
        "df = df.drop([\"種類\", \"都道府県名\"], axis=1)\n",
        "df = df.drop([\"今後の利用目的\", \"取引の事情等\"], axis=1)\n",
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xsk8yomfixyE"
      },
      "outputs": [],
      "source": [
        "def data_preprocess(df):\n",
        "  cat_fetures = [\"市区町村名\", \"地区名\", \"最寄駅：名称\", \"間取り\", \"建物の構造\", \"用途\", \"都市計画\", \"改装\"]\n",
        "  for col in cat_fetures:\n",
        "    lbl = preprocessing.LabelEncoder()\n",
        "    lbl.fit(df[col])\n",
        "    lbl.transform(df[col])\n",
        "    df[col] = lbl.transform(df[col])\n",
        "  return df\n",
        "\n",
        "df =data_preprocess(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs6C_OcPwqfF"
      },
      "outputs": [],
      "source": [
        "X = df.drop([\"取引価格（総額）\"], axis=1).values\n",
        "y = df[\"取引価格（総額）\"].values.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2VZMOEfw8GR"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=.3, random_state=0) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6ldOpvDmToc",
        "outputId": "9ca20480-de83-473a-e237-190dfca1a8ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 408634520678432.9| val_0_mse: 407646365474914.0|  0:00:38s\n",
            "epoch 10 | loss: 394629863639613.5| val_0_mse: 390631610476899.94|  0:04:37s\n",
            "epoch 20 | loss: 349143553181483.2| val_0_mse: 352070564735553.2|  0:08:38s\n",
            "epoch 30 | loss: 275533123272310.78| val_0_mse: 276012931483360.5|  0:12:39s\n",
            "epoch 40 | loss: 187787243002265.56| val_0_mse: 195936841897977.62|  0:16:39s\n",
            "epoch 50 | loss: 106000629746368.55| val_0_mse: 127062193485263.55|  0:20:37s\n",
            "epoch 60 | loss: 48830526410194.92| val_0_mse: 36833422263390.32|  0:24:37s\n",
            "epoch 70 | loss: 27847092432011.27| val_0_mse: 28339815557242.61|  0:28:37s\n",
            "epoch 80 | loss: 24290924058640.39| val_0_mse: 54290813784323.9|  0:32:38s\n",
            "epoch 90 | loss: 23870142254415.88| val_0_mse: 28954056190023.66|  0:36:42s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_val_0_mse = 19861851425624.242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ],
      "source": [
        "tabnet_params = dict(\n",
        "    seed = 0, \n",
        "    optimizer_params = dict(lr = 1e-2), \n",
        "    n_steps=3,\n",
        "    verbose = 10, \n",
        ")\n",
        "\n",
        "model = TabNetRegressor(**tabnet_params)\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set = [(X_valid, y_valid)],\n",
        "    batch_size = 32,  \n",
        "    max_epochs = 100, \n",
        "    patience = 100,  \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJod2MZ1mzDd",
        "outputId": "3b009e4e-a805-4190-c7a6-b9ee8f916bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE:  4549691.8667240115\n",
            "R2:  0.772548473442036\n"
          ]
        }
      ],
      "source": [
        "preds = model.predict(X_test)\n",
        "print(\"RMSE: \",np.sqrt(mean_squared_error(y_test, preds)))\n",
        "print(\"R2: \",r2_score(y_test, preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NaUVpHKmTlz",
        "outputId": "c758149f-8ae0-483d-f426-f7149eab1b17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 14669.01153| val_0_unsup_loss_numpy: 14351.98828125|  0:00:02s\n",
            "epoch 10 | loss: 3889.70766| val_0_unsup_loss_numpy: 15439.798828125|  0:00:27s\n",
            "epoch 20 | loss: 6.60601 | val_0_unsup_loss_numpy: 12291.1982421875|  0:00:51s\n",
            "epoch 30 | loss: 3.48947 | val_0_unsup_loss_numpy: 11272.36328125|  0:01:17s\n",
            "epoch 40 | loss: 1.7353  | val_0_unsup_loss_numpy: 11310.69921875|  0:01:40s\n",
            "epoch 50 | loss: 1.39659 | val_0_unsup_loss_numpy: 12056.05078125|  0:02:06s\n",
            "epoch 60 | loss: 1.25498 | val_0_unsup_loss_numpy: 9966.9208984375|  0:02:29s\n",
            "epoch 70 | loss: 1.2848  | val_0_unsup_loss_numpy: 5670.7333984375|  0:02:54s\n",
            "epoch 80 | loss: 1.26923 | val_0_unsup_loss_numpy: 8697.0791015625|  0:03:21s\n",
            "epoch 90 | loss: 1.23755 | val_0_unsup_loss_numpy: 11917.38671875|  0:03:44s\n",
            "epoch 100| loss: 1.27277 | val_0_unsup_loss_numpy: 10785.3115234375|  0:04:09s\n",
            "epoch 110| loss: 1.08464 | val_0_unsup_loss_numpy: 11902.8837890625|  0:04:33s\n",
            "epoch 120| loss: 1.14951 | val_0_unsup_loss_numpy: 9997.2919921875|  0:04:58s\n",
            "epoch 130| loss: 1.09406 | val_0_unsup_loss_numpy: 12324.89453125|  0:05:23s\n",
            "epoch 140| loss: 1.1002  | val_0_unsup_loss_numpy: 7276.671875|  0:05:47s\n",
            "epoch 150| loss: 1.07167 | val_0_unsup_loss_numpy: 9560.6474609375|  0:06:13s\n",
            "epoch 160| loss: 1.06671 | val_0_unsup_loss_numpy: 9983.3427734375|  0:06:35s\n",
            "epoch 170| loss: 1.03487 | val_0_unsup_loss_numpy: 7540.189453125|  0:07:01s\n",
            "\n",
            "Early stopping occurred at epoch 170 with best_epoch = 70 and best_val_0_unsup_loss_numpy = 5670.7333984375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ],
      "source": [
        "pretrainer = TabNetPretrainer(**tabnet_params)\n",
        "pretrainer.fit(\n",
        "    X_train,\n",
        "    eval_set=[X_valid],\n",
        "    max_epochs=5000,\n",
        "    patience=100,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_56XlZTwGcj",
        "outputId": "6b2112aa-027b-41d9-bc6d-5befdaa03c0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/abstract_model.py:231: UserWarning: Loading weights from unsupervised pretraining\n",
            "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 408734839290318.44| val_0_rmse: 20195181.8624|  0:00:01s\n",
            "epoch 10 | loss: 408600760109650.56| val_0_rmse: 20194490.37627|  0:00:24s\n",
            "epoch 20 | loss: 408734845784724.6| val_0_rmse: 20192822.99886|  0:00:47s\n",
            "epoch 30 | loss: 408554109707561.3| val_0_rmse: 20190186.75883|  0:01:08s\n",
            "epoch 40 | loss: 408143559325630.0| val_0_rmse: 20187340.29777|  0:01:32s\n",
            "epoch 50 | loss: 408192098517520.44| val_0_rmse: 20184421.43919|  0:01:53s\n",
            "epoch 60 | loss: 407715794437681.56| val_0_rmse: 20180288.76341|  0:02:16s\n",
            "epoch 70 | loss: 407916198824002.0| val_0_rmse: 20175293.37912|  0:02:38s\n",
            "epoch 80 | loss: 407307223767238.2| val_0_rmse: 20167842.83443|  0:03:00s\n",
            "epoch 90 | loss: 407449898294503.25| val_0_rmse: 20164396.09779|  0:03:22s\n",
            "epoch 100| loss: 407042341833827.1| val_0_rmse: 20156762.16249|  0:03:45s\n",
            "epoch 110| loss: 406496867998422.7| val_0_rmse: 20153934.45045|  0:04:08s\n",
            "epoch 120| loss: 406721340654096.44| val_0_rmse: 20157251.97683|  0:04:29s\n",
            "epoch 130| loss: 405968413836849.56| val_0_rmse: 20134747.58225|  0:04:52s\n",
            "epoch 140| loss: 405975177760900.1| val_0_rmse: 20124926.16518|  0:05:13s\n",
            "epoch 150| loss: 405437710445931.4| val_0_rmse: 20114186.16653|  0:05:36s\n",
            "epoch 160| loss: 404882417068362.3| val_0_rmse: 20101500.62719|  0:05:57s\n",
            "epoch 170| loss: 404265133501274.9| val_0_rmse: 20092291.65933|  0:06:20s\n",
            "epoch 180| loss: 404272848855832.75| val_0_rmse: 20091044.38282|  0:06:41s\n",
            "epoch 190| loss: 403116280622443.4| val_0_rmse: 20090019.04269|  0:07:04s\n",
            "epoch 200| loss: 403183778068414.0| val_0_rmse: 20047677.80045|  0:07:25s\n",
            "epoch 210| loss: 402459739452316.94| val_0_rmse: 20040352.71784|  0:07:48s\n",
            "epoch 220| loss: 402213861233829.1| val_0_rmse: 20019209.65543|  0:08:09s\n",
            "epoch 230| loss: 401186183150558.9| val_0_rmse: 20008948.6553|  0:08:32s\n",
            "epoch 240| loss: 400542015989033.3| val_0_rmse: 20014229.14463|  0:08:53s\n",
            "epoch 250| loss: 400000173609092.1| val_0_rmse: 20005606.51586|  0:09:16s\n",
            "epoch 260| loss: 399195940982916.1| val_0_rmse: 19993061.93471|  0:09:38s\n",
            "epoch 270| loss: 398398921477219.1| val_0_rmse: 19945234.27826|  0:10:01s\n",
            "epoch 280| loss: 398152902546597.1| val_0_rmse: 19923713.47057|  0:10:23s\n",
            "epoch 290| loss: 396810167830065.56| val_0_rmse: 19934186.23797|  0:10:46s\n",
            "epoch 300| loss: 395929862976941.44| val_0_rmse: 19887314.03783|  0:11:08s\n",
            "epoch 310| loss: 395395898311713.1| val_0_rmse: 19881467.66557|  0:11:30s\n",
            "epoch 320| loss: 394330245270627.1| val_0_rmse: 19838644.21639|  0:11:53s\n",
            "epoch 330| loss: 393378538751009.1| val_0_rmse: 19783993.6196|  0:12:15s\n",
            "epoch 340| loss: 392428923430185.3| val_0_rmse: 19756526.25233|  0:12:37s\n",
            "epoch 350| loss: 391853370752495.56| val_0_rmse: 19796540.16548|  0:13:00s\n",
            "epoch 360| loss: 390463159761887.06| val_0_rmse: 19704327.32819|  0:13:22s\n",
            "epoch 370| loss: 389865707946512.44| val_0_rmse: 19709907.82695|  0:13:45s\n",
            "epoch 380| loss: 388426192506483.56| val_0_rmse: 19659502.7265|  0:14:07s\n",
            "epoch 390| loss: 387108422287360.0| val_0_rmse: 19655445.89787|  0:14:30s\n",
            "epoch 400| loss: 386357896235602.56| val_0_rmse: 19643568.83553|  0:14:51s\n",
            "epoch 410| loss: 385118689930603.4| val_0_rmse: 19611372.40937|  0:15:15s\n",
            "epoch 420| loss: 383899706124089.8| val_0_rmse: 19585876.96303|  0:15:36s\n",
            "epoch 430| loss: 382886858017362.56| val_0_rmse: 19582426.09867|  0:16:00s\n",
            "epoch 440| loss: 381622313786599.25| val_0_rmse: 19609839.26072|  0:16:21s\n",
            "epoch 450| loss: 380293703321137.56| val_0_rmse: 19559793.71444|  0:16:45s\n",
            "epoch 460| loss: 378848063656068.1| val_0_rmse: 19569281.54806|  0:17:06s\n",
            "epoch 470| loss: 377856325616673.1| val_0_rmse: 19398306.93111|  0:17:29s\n",
            "epoch 480| loss: 376332805032530.5| val_0_rmse: 19369610.87954|  0:17:51s\n",
            "epoch 490| loss: 374637329890799.44| val_0_rmse: 19309590.61445|  0:18:14s\n",
            "epoch 500| loss: 373241255533799.25| val_0_rmse: 19310304.52945|  0:18:35s\n",
            "epoch 510| loss: 372002524402853.1| val_0_rmse: 19283942.9312|  0:18:58s\n",
            "epoch 520| loss: 370385302526150.2| val_0_rmse: 19346162.09493|  0:19:21s\n",
            "epoch 530| loss: 368758652936456.25| val_0_rmse: 19243683.62857|  0:19:43s\n",
            "epoch 540| loss: 367078764369589.7| val_0_rmse: 19068593.52051|  0:20:06s\n",
            "epoch 550| loss: 365650667178050.06| val_0_rmse: 19102479.28916|  0:20:27s\n",
            "epoch 560| loss: 364418465090130.56| val_0_rmse: 19267526.38672|  0:20:50s\n",
            "epoch 570| loss: 362283097839285.7| val_0_rmse: 18984034.62884|  0:21:12s\n",
            "epoch 580| loss: 360614427276717.44| val_0_rmse: 18930786.51991|  0:21:34s\n",
            "epoch 590| loss: 359355606782612.6| val_0_rmse: 18815251.93054|  0:21:56s\n",
            "epoch 600| loss: 357634913861632.0| val_0_rmse: 18973511.92441|  0:22:19s\n",
            "epoch 610| loss: 355731909969986.1| val_0_rmse: 18954190.03478|  0:22:40s\n",
            "epoch 620| loss: 354245483269219.1| val_0_rmse: 18673964.70911|  0:23:04s\n",
            "epoch 630| loss: 351859224118304.94| val_0_rmse: 18811527.83102|  0:23:25s\n",
            "epoch 640| loss: 350512730222988.3| val_0_rmse: 18614933.06665|  0:23:49s\n",
            "epoch 650| loss: 348828262017354.3| val_0_rmse: 18376114.86866|  0:24:10s\n",
            "epoch 660| loss: 346813242607682.06| val_0_rmse: 18899026.96109|  0:24:34s\n",
            "epoch 670| loss: 344581026442074.8| val_0_rmse: 18683345.02018|  0:24:54s\n",
            "epoch 680| loss: 342772562703789.4| val_0_rmse: 18425192.38854|  0:25:18s\n",
            "epoch 690| loss: 341075097026560.0| val_0_rmse: 18583621.58268|  0:25:39s\n",
            "epoch 700| loss: 338837975419474.5| val_0_rmse: 18457231.08828|  0:26:02s\n",
            "epoch 710| loss: 337126113808516.0| val_0_rmse: 18514677.12347|  0:26:23s\n",
            "epoch 720| loss: 335122203080637.94| val_0_rmse: 18517369.5231|  0:26:47s\n",
            "epoch 730| loss: 332831158418927.5| val_0_rmse: 18319726.86349|  0:27:07s\n",
            "epoch 740| loss: 330984278103205.25| val_0_rmse: 18143862.93097|  0:27:31s\n",
            "epoch 750| loss: 328433688827573.7| val_0_rmse: 18024513.2264|  0:27:51s\n",
            "epoch 760| loss: 326681338923602.56| val_0_rmse: 18171499.3384|  0:28:15s\n",
            "epoch 770| loss: 324403285239081.3| val_0_rmse: 18195604.8156|  0:28:36s\n",
            "epoch 780| loss: 322386328331561.3| val_0_rmse: 18115906.12797|  0:28:59s\n",
            "epoch 790| loss: 319783688555090.56| val_0_rmse: 17964284.94944|  0:29:20s\n",
            "epoch 800| loss: 318337075811493.2| val_0_rmse: 18142372.95654|  0:29:43s\n",
            "epoch 810| loss: 315938947050859.5| val_0_rmse: 17591151.34944|  0:30:05s\n",
            "epoch 820| loss: 314172265074820.1| val_0_rmse: 17576038.76855|  0:30:28s\n",
            "epoch 830| loss: 311502327014168.8| val_0_rmse: 17850197.92506|  0:30:50s\n",
            "epoch 840| loss: 309408795645621.75| val_0_rmse: 17634660.30887|  0:31:12s\n",
            "epoch 850| loss: 307026871510841.9| val_0_rmse: 17432033.46736|  0:31:34s\n",
            "epoch 860| loss: 304522995416559.56| val_0_rmse: 17117191.0683|  0:31:56s\n",
            "epoch 870| loss: 302622726752322.06| val_0_rmse: 17637240.47959|  0:32:18s\n",
            "epoch 880| loss: 300217831361635.1| val_0_rmse: 17338189.69331|  0:32:40s\n",
            "epoch 890| loss: 297833312170380.5| val_0_rmse: 17456886.94256|  0:33:03s\n",
            "epoch 900| loss: 295223519887888.5| val_0_rmse: 17872010.51198|  0:33:24s\n",
            "epoch 910| loss: 292367622082692.06| val_0_rmse: 16942389.36644|  0:33:47s\n",
            "epoch 920| loss: 290145947420738.25| val_0_rmse: 16896812.27353|  0:34:07s\n",
            "epoch 930| loss: 287984013718957.44| val_0_rmse: 16720135.80044|  0:34:31s\n",
            "epoch 940| loss: 285326967595800.8| val_0_rmse: 16973059.30751|  0:34:51s\n",
            "epoch 950| loss: 282806547542940.94| val_0_rmse: 16570869.22112|  0:35:15s\n",
            "epoch 960| loss: 280368834294156.38| val_0_rmse: 16496463.54467|  0:35:35s\n",
            "epoch 970| loss: 278162233690178.06| val_0_rmse: 16434687.47477|  0:35:58s\n",
            "epoch 980| loss: 275301709161769.28| val_0_rmse: 16706073.88212|  0:36:19s\n",
            "epoch 990| loss: 272725778171970.06| val_0_rmse: 16436173.15057|  0:36:42s\n",
            "epoch 1000| loss: 270527082342730.3| val_0_rmse: 16679774.57962|  0:37:04s\n",
            "epoch 1010| loss: 267508592748874.3| val_0_rmse: 16641709.77402|  0:37:26s\n",
            "epoch 1020| loss: 264882748459074.06| val_0_rmse: 16374568.03334|  0:37:47s\n",
            "epoch 1030| loss: 262391995936107.34| val_0_rmse: 16248242.64104|  0:38:10s\n",
            "epoch 1040| loss: 259377832157976.78| val_0_rmse: 15724629.52452|  0:38:32s\n",
            "epoch 1050| loss: 257052720547377.56| val_0_rmse: 16559071.86365|  0:38:54s\n",
            "epoch 1060| loss: 254488598011639.78| val_0_rmse: 16433376.2481|  0:39:16s\n",
            "epoch 1070| loss: 251805955810072.78| val_0_rmse: 15808230.17644|  0:39:38s\n",
            "epoch 1080| loss: 248884537023190.72| val_0_rmse: 15379401.14235|  0:40:00s\n",
            "epoch 1090| loss: 246742127130029.44| val_0_rmse: 15833619.22456|  0:40:23s\n",
            "epoch 1100| loss: 243704876820281.78| val_0_rmse: 15893129.04463|  0:40:45s\n",
            "epoch 1110| loss: 241637969811125.7| val_0_rmse: 15652651.5584|  0:41:07s\n",
            "epoch 1120| loss: 238548805383068.9| val_0_rmse: 15191909.99022|  0:41:29s\n",
            "epoch 1130| loss: 236253487402083.1| val_0_rmse: 15286779.39777|  0:41:51s\n",
            "epoch 1140| loss: 233318909324651.34| val_0_rmse: 14867600.88055|  0:42:12s\n",
            "epoch 1150| loss: 230636312042727.22| val_0_rmse: 15406687.3196|  0:42:35s\n",
            "epoch 1160| loss: 227712273304146.56| val_0_rmse: 15021830.62731|  0:42:57s\n",
            "epoch 1170| loss: 225305222311803.88| val_0_rmse: 14796097.76865|  0:43:20s\n",
            "epoch 1180| loss: 222547062613817.78| val_0_rmse: 14797862.54558|  0:43:41s\n",
            "epoch 1190| loss: 219815333525437.94| val_0_rmse: 14962231.54667|  0:44:04s\n",
            "epoch 1200| loss: 216912648394421.7| val_0_rmse: 15127551.06681|  0:44:26s\n",
            "epoch 1210| loss: 214271726258242.03| val_0_rmse: 15119787.98264|  0:44:49s\n",
            "epoch 1220| loss: 211722203688827.88| val_0_rmse: 14580557.00059|  0:45:11s\n",
            "epoch 1230| loss: 209085544047913.28| val_0_rmse: 14764724.75226|  0:45:35s\n",
            "epoch 1240| loss: 205984582531005.94| val_0_rmse: 14405608.34796|  0:45:56s\n",
            "epoch 1250| loss: 203394264807886.44| val_0_rmse: 13977797.10771|  0:46:20s\n",
            "epoch 1260| loss: 200912050805462.72| val_0_rmse: 14525047.69737|  0:46:41s\n",
            "epoch 1270| loss: 198018274917343.0| val_0_rmse: 14509350.89829|  0:47:05s\n",
            "epoch 1280| loss: 195104983338611.62| val_0_rmse: 13462722.30538|  0:47:25s\n",
            "epoch 1290| loss: 192697081037857.0| val_0_rmse: 13161147.1958|  0:47:49s\n",
            "epoch 1300| loss: 189992790274444.38| val_0_rmse: 13822013.49599|  0:48:09s\n",
            "epoch 1310| loss: 187098618768747.34| val_0_rmse: 13991795.55079|  0:48:33s\n",
            "epoch 1320| loss: 184604596312262.22| val_0_rmse: 13528922.16537|  0:48:54s\n",
            "epoch 1330| loss: 181675229454600.25| val_0_rmse: 13004732.26354|  0:49:17s\n",
            "epoch 1340| loss: 179314087960840.22| val_0_rmse: 13812023.21737|  0:49:38s\n",
            "epoch 1350| loss: 176688785412756.66| val_0_rmse: 13168440.19859|  0:50:00s\n",
            "epoch 1360| loss: 173808457275061.7| val_0_rmse: 13454881.85991|  0:50:22s\n",
            "epoch 1370| loss: 171012591595916.38| val_0_rmse: 12815708.10132|  0:50:43s\n",
            "epoch 1380| loss: 168262687370603.34| val_0_rmse: 14164025.4996|  0:51:07s\n",
            "epoch 1390| loss: 165225100975335.22| val_0_rmse: 13224020.85485|  0:51:28s\n",
            "epoch 1400| loss: 162820850154462.94| val_0_rmse: 11669206.79918|  0:51:51s\n",
            "epoch 1410| loss: 160545341735969.06| val_0_rmse: 12615916.125|  0:52:11s\n",
            "epoch 1420| loss: 157770953328706.06| val_0_rmse: 12531754.22098|  0:52:35s\n",
            "epoch 1430| loss: 155141044893629.94| val_0_rmse: 13022193.57348|  0:52:56s\n",
            "epoch 1440| loss: 152796827822410.3| val_0_rmse: 13496999.23605|  0:53:19s\n",
            "epoch 1450| loss: 150109721257785.88| val_0_rmse: 11851471.4072|  0:53:40s\n",
            "epoch 1460| loss: 147214183491385.88| val_0_rmse: 11579505.75332|  0:54:02s\n",
            "epoch 1470| loss: 144845498474231.72| val_0_rmse: 12643563.02532|  0:54:25s\n",
            "epoch 1480| loss: 142136114202161.47| val_0_rmse: 11543192.04944|  0:54:47s\n",
            "epoch 1490| loss: 139847922208371.61| val_0_rmse: 12077509.8819|  0:55:09s\n",
            "epoch 1500| loss: 136969193859402.33| val_0_rmse: 12073619.82822|  0:55:31s\n",
            "epoch 1510| loss: 134269268419352.78| val_0_rmse: 11089872.40142|  0:55:53s\n",
            "epoch 1520| loss: 132036821161125.16| val_0_rmse: 11053647.92868|  0:56:16s\n",
            "epoch 1530| loss: 129047096104101.16| val_0_rmse: 11273468.42901|  0:56:37s\n",
            "epoch 1540| loss: 126784428479653.16| val_0_rmse: 11489358.87089|  0:57:00s\n",
            "epoch 1550| loss: 124369580411474.58| val_0_rmse: 11765515.4993|  0:57:20s\n",
            "epoch 1560| loss: 121765469110800.5| val_0_rmse: 10907378.30091|  0:57:44s\n",
            "epoch 1570| loss: 119400483199174.19| val_0_rmse: 10548065.11588|  0:58:04s\n",
            "epoch 1580| loss: 116778611591762.58| val_0_rmse: 11450097.61878|  0:58:28s\n",
            "epoch 1590| loss: 114301238627955.61| val_0_rmse: 10504785.54183|  0:58:49s\n",
            "epoch 1600| loss: 112004604717914.84| val_0_rmse: 10082054.87941|  0:59:11s\n",
            "epoch 1610| loss: 109730331860199.22| val_0_rmse: 12336550.47011|  0:59:33s\n",
            "epoch 1620| loss: 107434221832258.06| val_0_rmse: 9582729.90615|  0:59:54s\n",
            "epoch 1630| loss: 104865165712615.22| val_0_rmse: 11034989.51287|  1:00:18s\n",
            "epoch 1640| loss: 102568260119915.36| val_0_rmse: 9079256.38231|  1:00:38s\n",
            "epoch 1650| loss: 100146854325082.84| val_0_rmse: 9987760.5443|  1:01:02s\n",
            "epoch 1660| loss: 97967713964692.64| val_0_rmse: 8639597.91728|  1:01:23s\n",
            "epoch 1670| loss: 95680801639523.11| val_0_rmse: 9367569.97693|  1:01:47s\n",
            "epoch 1680| loss: 93756518284783.5| val_0_rmse: 9600287.49387|  1:02:08s\n",
            "epoch 1690| loss: 91582987467742.97| val_0_rmse: 10444497.20208|  1:02:31s\n",
            "epoch 1700| loss: 89258487684327.22| val_0_rmse: 9273723.4026|  1:02:53s\n",
            "epoch 1710| loss: 87458417424846.45| val_0_rmse: 10370913.01199|  1:03:15s\n",
            "epoch 1720| loss: 84885070126311.22| val_0_rmse: 9386394.95052|  1:03:37s\n",
            "epoch 1730| loss: 82611369588141.42| val_0_rmse: 9288132.74409|  1:04:00s\n",
            "epoch 1740| loss: 80644270507569.55| val_0_rmse: 9889312.68521|  1:04:21s\n",
            "epoch 1750| loss: 78211734112322.06| val_0_rmse: 9805408.63173|  1:04:44s\n",
            "epoch 1760| loss: 76433793271345.58| val_0_rmse: 9731180.51766|  1:05:05s\n",
            "epoch 1770| loss: 74789434653662.97| val_0_rmse: 9614669.90833|  1:05:29s\n",
            "epoch 1780| loss: 72844776046591.97| val_0_rmse: 8954531.72353|  1:05:50s\n",
            "epoch 1790| loss: 70828418653943.77| val_0_rmse: 9150635.7546|  1:06:13s\n",
            "epoch 1800| loss: 68803906181318.195| val_0_rmse: 8469282.49568|  1:06:34s\n",
            "epoch 1810| loss: 67097479576542.97| val_0_rmse: 7651381.82167|  1:06:57s\n",
            "epoch 1820| loss: 65324873619654.195| val_0_rmse: 7584811.31132|  1:07:19s\n",
            "epoch 1830| loss: 63460279134538.32| val_0_rmse: 7311598.43033|  1:07:40s\n",
            "epoch 1840| loss: 61677215018875.86| val_0_rmse: 8317704.53749|  1:08:03s\n",
            "epoch 1850| loss: 59967986348428.39| val_0_rmse: 8134256.98851|  1:08:24s\n",
            "epoch 1860| loss: 58222820610708.64| val_0_rmse: 8099535.58169|  1:08:47s\n",
            "epoch 1870| loss: 56585931371949.42| val_0_rmse: 8463596.18221|  1:09:08s\n",
            "epoch 1880| loss: 54585648987631.484| val_0_rmse: 7973416.10033|  1:09:31s\n",
            "epoch 1890| loss: 52920792535700.64| val_0_rmse: 7034139.52073|  1:09:53s\n",
            "epoch 1900| loss: 51456865299290.836| val_0_rmse: 8058567.03454|  1:10:16s\n",
            "epoch 1910| loss: 50190243940946.58| val_0_rmse: 6952927.07827|  1:10:37s\n",
            "epoch 1920| loss: 48471779683691.36| val_0_rmse: 7820329.26919|  1:11:01s\n",
            "epoch 1930| loss: 46759570351401.28| val_0_rmse: 7668950.90145|  1:11:21s\n",
            "epoch 1940| loss: 45638351982724.13| val_0_rmse: 6093214.8234|  1:11:44s\n",
            "epoch 1950| loss: 43852461717966.45| val_0_rmse: 6640727.95984|  1:12:06s\n",
            "epoch 1960| loss: 42425665843067.87| val_0_rmse: 7538931.61251|  1:12:29s\n",
            "epoch 1970| loss: 41357962869726.96| val_0_rmse: 6709094.84716|  1:12:50s\n",
            "epoch 1980| loss: 40079390383335.22| val_0_rmse: 6142044.85049|  1:13:13s\n",
            "epoch 1990| loss: 38958965549914.836| val_0_rmse: 5210205.05578|  1:13:35s\n",
            "epoch 2000| loss: 37748424606753.05| val_0_rmse: 6666974.84458|  1:13:57s\n",
            "epoch 2010| loss: 36482123368514.06| val_0_rmse: 6133284.0773|  1:14:19s\n",
            "epoch 2020| loss: 35094186231874.055| val_0_rmse: 6353157.75747|  1:14:41s\n",
            "epoch 2030| loss: 34124645058097.547| val_0_rmse: 6033971.28511|  1:15:03s\n",
            "epoch 2040| loss: 33356636538417.547| val_0_rmse: 5568104.88534|  1:15:26s\n",
            "epoch 2050| loss: 32513162951118.453| val_0_rmse: 5385864.00507|  1:15:48s\n",
            "epoch 2060| loss: 31160365963990.71| val_0_rmse: 5863328.12128|  1:16:10s\n",
            "epoch 2070| loss: 30187638336875.355| val_0_rmse: 5418173.32054|  1:16:32s\n",
            "epoch 2080| loss: 28942670681781.68| val_0_rmse: 6720959.656|  1:16:54s\n",
            "epoch 2090| loss: 28092096679011.098| val_0_rmse: 6272342.75005|  1:17:14s\n",
            "epoch 2100| loss: 27484388166755.098| val_0_rmse: 5718056.91915|  1:17:37s\n",
            "epoch 2110| loss: 26890644454366.973| val_0_rmse: 4786966.144|  1:17:58s\n",
            "epoch 2120| loss: 25851219207993.805| val_0_rmse: 5363802.16815|  1:18:21s\n",
            "epoch 2130| loss: 24877479332963.098| val_0_rmse: 5111151.13445|  1:18:43s\n",
            "epoch 2140| loss: 24385299609533.93| val_0_rmse: 4984957.00618|  1:19:05s\n",
            "epoch 2150| loss: 23551031369463.742| val_0_rmse: 5686019.69599|  1:19:26s\n",
            "epoch 2160| loss: 23086159676977.547| val_0_rmse: 4686241.04193|  1:19:49s\n",
            "epoch 2170| loss: 22266090779548.902| val_0_rmse: 5420690.15715|  1:20:10s\n",
            "epoch 2180| loss: 21842388548574.973| val_0_rmse: 4953970.90758|  1:20:32s\n",
            "epoch 2190| loss: 21292021211928.773| val_0_rmse: 4737407.06913|  1:20:54s\n",
            "epoch 2200| loss: 20922719543560.258| val_0_rmse: 4799592.16267|  1:21:16s\n",
            "epoch 2210| loss: 20808984496194.074| val_0_rmse: 4465454.9922|  1:21:38s\n",
            "epoch 2220| loss: 19680047999306.33| val_0_rmse: 4437431.75289|  1:22:00s\n",
            "epoch 2230| loss: 19548262561725.945| val_0_rmse: 5234058.90316|  1:22:22s\n",
            "epoch 2240| loss: 19240570483612.902| val_0_rmse: 4486497.49061|  1:22:44s\n",
            "epoch 2250| loss: 18779380307637.68| val_0_rmse: 4177485.2329|  1:23:06s\n",
            "epoch 2260| loss: 18779638764709.164| val_0_rmse: 8975173.98893|  1:23:28s\n",
            "epoch 2270| loss: 18176727690603.355| val_0_rmse: 4252964.38896|  1:23:48s\n",
            "epoch 2280| loss: 18217689263467.355| val_0_rmse: 4215253.71628|  1:24:12s\n",
            "epoch 2290| loss: 18004493602948.13| val_0_rmse: 4443652.93864|  1:24:33s\n",
            "epoch 2300| loss: 17600019549811.617| val_0_rmse: 4173694.90469|  1:24:57s\n",
            "epoch 2310| loss: 17424401775054.451| val_0_rmse: 4445147.10873|  1:25:17s\n",
            "epoch 2320| loss: 17108068652725.678| val_0_rmse: 5177646.60932|  1:25:41s\n",
            "epoch 2330| loss: 17108960043800.773| val_0_rmse: 4205400.49567|  1:26:02s\n",
            "epoch 2340| loss: 17048225270354.58| val_0_rmse: 5054480.33161|  1:26:25s\n",
            "epoch 2350| loss: 17010821448208.514| val_0_rmse: 5226354.53176|  1:26:46s\n",
            "epoch 2360| loss: 16665214045811.611| val_0_rmse: 5371922.70043|  1:27:09s\n",
            "epoch 2370| loss: 16872295764100.129| val_0_rmse: 4125609.48111|  1:27:31s\n",
            "epoch 2380| loss: 16785453951306.322| val_0_rmse: 4219358.74725|  1:27:52s\n",
            "epoch 2390| loss: 16546380585158.193| val_0_rmse: 4528850.40389|  1:28:15s\n",
            "epoch 2400| loss: 16753059447312.514| val_0_rmse: 4897353.28029|  1:28:37s\n",
            "epoch 2410| loss: 16686577259685.16| val_0_rmse: 4194862.90434|  1:28:59s\n",
            "epoch 2420| loss: 16526945228998.193| val_0_rmse: 4435156.02243|  1:29:20s\n",
            "epoch 2430| loss: 16391367294976.0| val_0_rmse: 4121900.8566|  1:29:43s\n",
            "epoch 2440| loss: 16503372428717.42| val_0_rmse: 4157282.82755|  1:30:04s\n",
            "epoch 2450| loss: 16436344778619.871| val_0_rmse: 4215151.05075|  1:30:26s\n",
            "epoch 2460| loss: 16207423725303.742| val_0_rmse: 4118173.14872|  1:30:49s\n",
            "epoch 2470| loss: 16413439616825.807| val_0_rmse: 4135833.06047|  1:31:09s\n",
            "epoch 2480| loss: 16194325590412.389| val_0_rmse: 4141809.89966|  1:31:32s\n",
            "epoch 2490| loss: 16289828877741.42| val_0_rmse: 4217264.96864|  1:31:53s\n",
            "epoch 2500| loss: 16149724511727.486| val_0_rmse: 4185907.17109|  1:32:16s\n",
            "epoch 2510| loss: 16043514519287.742| val_0_rmse: 4125147.40993|  1:32:38s\n",
            "epoch 2520| loss: 15948743239481.807| val_0_rmse: 4237242.38637|  1:32:59s\n",
            "epoch 2530| loss: 16145181065744.514| val_0_rmse: 4079699.95039|  1:33:22s\n",
            "epoch 2540| loss: 16167855608468.645| val_0_rmse: 4640693.37332|  1:33:42s\n",
            "epoch 2550| loss: 16354251019429.16| val_0_rmse: 4563528.92851|  1:34:06s\n",
            "epoch 2560| loss: 16052172002469.16| val_0_rmse: 4160573.29714|  1:34:27s\n",
            "epoch 2570| loss: 16137087175250.58| val_0_rmse: 4086469.83708|  1:34:50s\n",
            "epoch 2580| loss: 15954876259030.709| val_0_rmse: 4641179.81707|  1:35:11s\n",
            "epoch 2590| loss: 16100226278697.291| val_0_rmse: 4137868.995|  1:35:34s\n",
            "epoch 2600| loss: 16051576276001.035| val_0_rmse: 4280535.7736|  1:35:55s\n",
            "epoch 2610| loss: 16050114188981.678| val_0_rmse: 4255135.53765|  1:36:16s\n",
            "epoch 2620| loss: 15972329569775.486| val_0_rmse: 4542273.8179|  1:36:38s\n",
            "epoch 2630| loss: 16104340282070.709| val_0_rmse: 4072583.48737|  1:37:00s\n",
            "epoch 2640| loss: 16134586490615.742| val_0_rmse: 4122136.21241|  1:37:22s\n",
            "epoch 2650| loss: 16039021235827.611| val_0_rmse: 4534585.52267|  1:37:44s\n",
            "epoch 2660| loss: 15954649056289.035| val_0_rmse: 4113335.92899|  1:38:06s\n",
            "epoch 2670| loss: 16098061645757.938| val_0_rmse: 4055048.68625|  1:38:28s\n",
            "epoch 2680| loss: 16083024930617.807| val_0_rmse: 4053405.77301|  1:38:50s\n",
            "epoch 2690| loss: 15915762716804.129| val_0_rmse: 4458169.16045|  1:39:12s\n",
            "epoch 2700| loss: 16198562683078.193| val_0_rmse: 4128299.78417|  1:39:33s\n",
            "epoch 2710| loss: 16148878784445.938| val_0_rmse: 4121587.62925|  1:39:57s\n",
            "\n",
            "Early stopping occurred at epoch 2719 with best_epoch = 2619 and best_val_0_rmse = 4020604.00503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ],
      "source": [
        "model = TabNetRegressor(**tabnet_params)\n",
        "\n",
        "model.fit(\n",
        "  X_train, y_train,\n",
        "  eval_set=[(X_valid, y_valid)],\n",
        "  max_epochs=5000,\n",
        "  patience=100,\n",
        "  eval_metric={'rmse'}, \n",
        "  from_unsupervised=pretrainer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1yRvRIp6AUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa336f8b-5f68-4c55-8045-19016b961b74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE:  4111006.248914816\n",
            "R2:  0.8142960417553144\n"
          ]
        }
      ],
      "source": [
        "preds = model.predict(X_test)\n",
        "print(\"RMSE: \",np.sqrt(mean_squared_error(y_test, preds)))\n",
        "print(\"R2: \",r2_score(y_test, preds))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "WfOafDeH1vzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYC4ZSnExm0I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "9c5a71be-6bf2-4b39-e574-9f377b3d1fc9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAccAAAD3CAYAAABo8Z+rAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwRUlEQVR4nO3de7zlY93/8dd7HIfBYMY5CbdTphTddf/qzq4kKkxyI7q170gqpZJDJ1EqklI6kJJUEsoIJaZsiSRCUpSKximUQ3vMMGM+vz8+15r1na+1D7NnH9ba+/18PPZjr/U9rWtdan/m+n6v6/NRRGBmZmZNk8a6AWZmZu3GwdHMzKzGwdHMzKzGwdHMzKzGwdHMzKxm+bFugPVv6tSpsfnmm491M9rC3LlzWXXVVce6GW3BfZHcD03ui6a5c+dy++23PxwR04d6DQfHNrfuuutyww03jHUz2kJPTw9dXV1j3Yy24L5I7ocm90VTT08Pr3jFK+5elmv4tqqZmVmNg6OZmVmNg6OZmVmNg6OZmVmNg6OZmVmNg6OZmVmNg6OZmVmNg6OZmVmNg6OZmVmNg6OZmVmNg+MokvROSU5+aGbW5sZdblVJBwELI+Ks2vZTgO36OO3eiNhf0ibA1cATwDxgPWCTiJjfx2cdC1wSETdUtp0GHBMRD9aOfSFwArC3JICFwJsi4qGl+4ZmZjbSOj44StoROK6yaX0gJHVXtp1ABsadgKcjIsq5OwFzIuKOyrHfB24H7gS6gcslLars/0JEXNhPk1amNiKXtCHwWWDjiHhU0muAgx0YzczaU8cHx4i4CuhqvC9BcWFEfKd6nKSjgRWBsyV9ErgF+DCw2wAfsTMwDTg+IrrLtbYDTgFmALtJuprmqHQLYGtJJ0XEBZJeBJwELAL+W9IjwCeA1wzpC5uZ2Yjr+OAIIGkv4F3A0yw5cpwE/CgiTimHPgUcAJwKrA5cGBG9tcvtw5K3VZ8hIm6W9GrgXuAw4Brg2RFxV7mt+tmIuLMc/jpgL2ABect2eeB1EfFIP9/nYOBggOnTp9PT0zO4jhjnent73ReF+yK5H5rcF029vfU/60tvXARHMoh9ISJmVUeOkrYFDqoeGBFPSPohcDJwlyQ1brMW9duqfXkt8FC5zoHAaZJ2rR8UEcdKWh74APAA0B0R9/X3ZSLia8DXALbccstwjbbkenVN7ovkfmhyXzQNxz8SxktwHCxJOpR89rgdGbC+LultEbGo3zOXvMiKwHuAWcBvgP2BrwDvrB23Ghmc9wS2JW/lnlMm5AAQEV1D/jZmZjYixm1wLEsmJgPVUeFu5HfeswTD4yW9tnbMPsBfKu9bBc2ZwHeBjYF7yoh1eWBtlpwc9BTwS/L55JX1QCipZ2m/l5mZjbzxEhzvBR6ubXsXsCs5GabhMDIQzqyO3oAjJf0PeZt0t4i4ubpTtYOBC8mlGB9rbIiIhcA/aqPCJ8mRJZLWczA0M+sM4yI4tlpaERGfAT5T2/yqEsT6c3P1jaRPA3sAF1SuvaDsqx73AnKiz5rAES2u+4BHjmZmnWFcBMeq+uL/yvauIV7vg8AH+9h3bOX1TcDL+rnUzsPVJjMzG1lOHzdKIuKpsW6DmZkNjoOjmZlZjYOjmZlZjYPjKHJVDjOzzjDuJuQMB0kbAR+JiEMkzSAz5lwYEa+vHHMKA1T5qF3TVTnMzDqEg+PADicz6SBpErB+RNzL4Kt8uCqHmVmH8W3VmpJQ/Hxgd0nnls27Ac8j1zpeWjl8ReB8SS8ogfPDZEKC6vVeRGbTgazK8TKyKscSOV/NzKx9eORYExFXSPoj8BHg9+So8UbgzxGxp6RZlcMHU+XDVTmGiasONLkvkvuhyX3R5KocIywiviRpB+B79FF/caAqH67KMXxcdaDJfZHcD03ui6bh+EeCb6suhZJKbo0lN+lQ4G3kM8jHyCofk8rO1SS9D7gSOIq8DXuOpJ7Gz2i238zMBscjx9YEbC3pIjLgQVbVOFnSdpJeXLYNVOXDVTnMzDqQg2ONpJ3JCTMXAmcCJwJrlsC4IrALzZJW/Vb5KLNRXZXDzKzDODg+01XASyrLMy4CviRpFXJSzd+B08mSWIOp8tHgqhxmZh3CwbGm1GCsvp8FzGpxaNdSXtpVOczMOoQn5IwSV+UwM+scDo5mZmY1vq3a5uYteJpNjr504AMngMNnLKTbfQFMvL6464TXjXUTbILxyHEYDKbahqQtJU2StGNJCmBmZm2q7f9IS3oQ+ENt8zYRsU4JMttVtu8NPAz8vLLtZmBl4E7gH8BKwN+Ai8gUbf8CNgN2jYjbh9C+PqttSNoYOBp4MXAt8GnghIj4r6X9HDMzGz2dPnKcBhwPTCk/jwFPVt5/Gpja4rzry+8jI2InmonBl0qt2kZX+bzHKtU27gWOJSt1vBtYC1hb0o8lnSvprBJczcysjbT9yBH4BZllpurh8vvfZN7TY8v7zcm1iHeX998C5gLLAdcBlwDrAmeTCcH7JWkdYLmIuL/FvhcBJwGLyGobj5DJA6o5WF8PvBt4nqTZ5dj9yvZLIuKGgdpgZmajr22Do6TXAUeUtzNb7O8BPkeWkXoc2B74GTAHeC7wEHB+RMyTNIUcZW5Bjt42I1PEHS3pKGAFMhtO3YfIkWd3i30DVtuIiIskXUMWS94F+CTwdNn9LEkrRsS1A3aGmZmNKlUKSLQdSe8l85M+Qo62rq7svgtYB3gL+dzxj8D8yv4NgPvIUeIPWfKZ4x+AHuAWMml491Jkuqm2r1Ft45X0UW2jJB5/F3ANGRyPBO4BfgUcUW7r1s9ZXLJq2rTp2x9zyhlL27Rxad3J8I95Y92K9jDR+mLGhmu03N7b28uUKVNGuTXtyX3R1Nvby2677XZjROww1Gu07cix4inyOeI84Fnkc7wngT0i4h3A2ZIOJEd/kM/8vidpdiPwSFodeAP5jHUN4K1k/cW5wG3Ai8hgNSiSViOLFe8JbEsG2XOq+VUjokvSmsB/kXUhZ5fjrycD9z+BByVtExFLTDiqlqzaeNPN4+RbO+E/08g7fMZC3BdpovXFXft3tdzuMk1N7oumiVKy6hBydDafTAL+JuBAciJMwz7kSLAH+N8W13g+8HYyoHWRt1Q3I59Nzirbn0HSKZLOarGrUW3j5cAtEdFV/akctxdwGkBEfBt4BfCTyv4LyRGxmZm1kbb9p2eZDDODXJaxQvn5N1kRY1vyWV/D1pQgRI4s67Yjq2M8AdwEfAqYWmaVPiRpmqSXR8Qvaud9ipzMs4SSf3Uw1Ta+GRELJb2nvD84IuaoOcT8Ec1nkGZm1ibaNjiSo9rLgD8Dj5JrCS8GziKD1hclHRMRvwO2ioi5AJL2knQ1edu04VxymceLySB6C/Dbyv53Ay+tNyAiHhxEO/ustlF/jhkRd0v6Hjlq/XI9ybmZmbWHtg2OEfEAcH5l076SVoiIxohxZuXYuZXXF5AzWKvXaqw7vBp4SYvP+jtZimooBqy2ERHVtr5paS4+eYXluMOps4B8jtDXs6eJxn1hNrI64ZnjYpXA2DZcbcPMbPzpqOBoZmY2GhwczczMahwczczMahwcl5GkqY3fJTmAmZl1uEHPVm3H0lGSVibTyN0OrA8cBnwGqC7BOIacobo7sCmZUm4+uRzk5aWNG0XE2QN81kZkEoLuxsSg8r1/KunlwA7kDNpDK+esQCY/PzIi7hnMdzIzs7E3XEs5GqWjTijvq6WjAD5MZraZXzuvWjpqtqTjh/DZl0VEt6RGlps/RcRe1QMk3UEmEbifXP84qbR5G+DVwG8l/SUirunncz4PHFabMftO4NyyXnG2pP0l7R4RP4KcXSvpiHLu3kP4bmZmNgaWJji2ZekoYJey6L4xctyylrFmZ2AyWZFjBpnTdA1gQzIReHfJ0drf528FPFpNLC5pezL122srhx4K/ETS0xFxKUBE3CvpcUlbRMSfBvquZmY29gasylErHdWXz5HlonYmS0c9yZKlo74SEb2ldNRlwLVk6ajvkKnf3ggEObp7a0T8tdaGU8h0b90t2jeJvEV6WkTcJekHwP5l95lkkvFpZFC+i6ypOJW89boBMJ1MSXdwybbTqg/eDvw7Is4p718CfKl8z/rayzuArYCjI+JX5fj9gVUiYlDlNapVOaZPn779eeedN5jTxj1XHWhyXyT3Q5P7omlUqnJExKWS/oOBS0f9iL5LR+0sqVE6anNgNfKZ41pksvBP0E/pqIh4bz9NPJssAbVjeQYZETEfQNKicsxk8rbvW4DvkoH4SfKZZ3eroFuzdjm2YQ6wZ0T8XdJzydutB0taFzgVeFXtezxE/qNhUKpVObbccstwpv3kqgNN7ovkfmhyXzQNR1WOpbmt2nalo2o2IwN19bbq1uX3i4FeMsCJrI5xOXAK0Egc/u6IuLWPaz9Mjj6BvFVa2bc90DhvdaC3RYCfRt7ONTOzDrA0wfEQMkD+lpy1eSn5DLFaImofoFGB4nPkc8iq55PlpoIcTdVLR32AFsGxv9uqFWeTQfeOFhNyIAPvesAe5K1VgPcyuJHjVcDhwDkt9r2NnGwEOcJ8tMUxXcDJA3yGmZm1iQGDYzuXjpK0fvnM5wK7kDUet5A0u3LYeeXzeoD3AasCXyn7TgbWL8d/LyK+0aoPIuKOso5xg9qknOOAX1SWaWxGLlOptnEDYI2IuKPVtc3MrP0MZuTYzqWjNgVuIEeoV0VESJrZYuT4ZmBeRCyS9H5gI2AhcHhE9AyiDyBHjidJ6i5LNH4E/Ak4UtLbgHeQk3sWf3ZZ53hSOdfMzDrEYCbktG3pqLIu8Zratr1aHPedyuvjgOMG+xmV8+bQnAULcEBEPFpen1F+6ucsqJ1jZmYdYEjp49qxdNRoqwRGMzMbZ5xb1czMrMbB0czMrKatg6Ok1w58lJmZ2fAatuAoaWdJcyT9QtJNkm6XtLGk5cvPpHLcTyXNLj+3SdqrbN+pmnhc0ibAwZVj6z8HVI69oPL6DEl7SuqStN4g2r2RpO+WmaWUtlavt5+kDSR9QtJytXMPLZ+zQmnTryT9rdG+sv2cUtHDzMw6xHBV5SAiLpd0EZmmbTvgNeRM0lvJRfebAVtHxGsa50jq7ueSbwBOjYiflSD3EWA2MKU6+7SqrCl8Lpnn9R1kYoF6IoK6xdU2JG1GJgY4X9KHyXWT+5JJ128iy2EdLqmLXIqygMx8syWZyPxVwMbAtxpZclyVw8ys8wxbcKz4IVmq6ivA6eSayD9TloOUgPjmcuz6wMf6uM7/AftJ+iYZfJ5NZppZrpSn2h94HvBBYJuSAu5fZG3HJ8lR8bn9NbRFtY37yuc8Qgb1I8v3+ByZ+ee5JZfqk2TgfVX5jG2Aj5N5ZB8HfifpeRGx0FU5zMw6z0gExz3JkeMmwK/JgLY2zXJXXcCBEXF3CTTPWBYiaQ+ayQNWI6t9nECOHCHXSE6OiJ9ImkwmI3g7sCYZ4H4DnBQDlRyBHYErG28iYp6kM8kqIU+TI8c3At8n13P+MyJuK7dJtyvnvoRMXnAUGSTnkwnVq64snzWo4FiryjEsSXTHg97eXvdF4b5I7ocm90VTb2/vMl9jpEeO1wAfItPMfbHs3xo4U1IjcM2mWSS54XHg24P8vJeSiQMOJUthvYMMXF0li82J/RQxXqLaRnn++RYyi89k4ABgZTITz7Vk5Y+VSvs+RuaJnQfsVC7xY3L02hgZN7gqxzBw1YEm90VyPzS5L5pGuyrHYC0eOUbEE5J+TZZwulWZAfzuiNgbQNLm5K3LJUTElZJ2HOiDyrO/e8hboWcBnyZvbX6PDGp/YslSU3VLVNsgA/s8Mpn6/eRzxdXJEeTawPER8aSkfYAPk3lUF5F5Xx8Gzi41Jes1xFyVw8ysgwxbcCy3GjclJ+Q8h2bKuSeAkLRKRDzBkhNT1iJHaUM1H/gy8NKIuFHSOeQzxFlltut7q4nCW6hX21gfeGV5/f/IZ48zyNu0twHflfTmiDhb0n+W77oVWaPy78AZkuaQo85FNHXhqhxmZh1jONc5rkk+m/sEmWwbSbuSt1GPAS4o9RyrtqF19Y6qjYGfkLNXjy8/+wFExHUR8VTt+OPL5Jx+J+OU8+8AppZZrpBlrf5YXp9FPie8nQx025KltarB/YdkTUjI0ePtwGHAKuW7uSqHmVkHGs6lHLdSiv5KqpaR2j8i5kpagww2F0s6DdgBWBHYfYBL/71FlY36M8qqj1RHjoNo+uJqG8AVpU07lck+TwONxOtPl7beUzl3z4h4oCw1+SbwxnIr+a3Af7gqh5lZZxqJZ45ExGXAZZImRcSisu37lf2HtDhnNs3ZqJDLJ57oo8rG0bX3e5XfZ1W23cUggmOt2sYCYC65tpGIuLxs37LFeYdWXj8g6bWN2bGN+pRlt6tymJl1mBEJjg2NwDjEcx8fzraMtEEsGzEzsw7R1rlVzczMxoKDo5mZWY2Do5mZWc2IPnPsRJKmAb8nl2WsDPSQqfAaFT5mAG8CvkEmGFiNXNe4M5m6DmBR9XmrpLcD90TEpeX9x4FbI6KxFtTMzNqIg2NrfwG+Q2bFWbNsa1QCefdgK5BUrrcVmUSg4eHKdc3MrM04OLa2GZkftTFyhGa+1Gptxn4rkFRMBR6VtFZE/IvMGrTqSDTczMyWnYNja5dFRHctR+qCiLhF0iWVbQNVIGlYSJa8Op9MNOBlH2ZmbczBsX9fBr5aXneTwa9qoAokDfeQ+V+vKO+nA3P6+lCXrGrNJXma3BfJ/dDkvmhq15JV48lzyKAIzQk5VX1WIKkddzZZHLmhC3hfXx/qklWtuSRPk/siuR+a3BdN7Vqyajz5eUTsCyBpcSLzpahAAkBEVGtGvgvojYhGgnMzM2szDo79e2Wp8AFZxLihUYGkh5yVukmLCiT7VlPgSZpE3oZ9iKwXaWZmbcrBsX/PiognASStKelyYM2lqUDSuFBELCoBc/6ofwszM1sqDo41EfEw5TljIzCW14+QC/3rx/dbgaR2rAOjmVkHcPq4YbIsFUjMzKy9ODiamZnV+LZqm5u34Gk2OfrSsW5GWzh8xkK63ReA+6LB/dC0rH1x1wmvG8bWdD6PHM3MzGo6fuQoqZvmQv2+fB54G5m27WTg2LJ9G+AP5fXHIuKqfj5nI+BEoDsiFvRxzPrkco0LI+IzklYAvgUcGRH3DOb7mJnZ2Ov44BgRZwFnNd5LuhA4sCT4prL9Z8ApEdEj6evANGB1Suaa/gJj8XngsL4CY9ELfBr4d7nmAklHlHP3Hvy3MjOzsdTxwRFA0pnAxuXt84HzJDV23wLcBBwCPFvSVTQTf28EzCzX+HdEfKOP628FPBoR97XYtxqwMCLmkdlyngf8vLE/Iu6V9LikLSLiT8v0Rc3MbFSMi+AIrBMRO0n6DrkYf3Ng34g4VtJlEXG4pCnAayNid0lvIYsUN6zaV2AsdgSurG6Q9BLyFu2NwEsl/ZKs5fj8iDi+dv6V5RoOjmZmHWC8BMeqnwGTgR83NiiHkTOADSV9lKzXuEnlnFXJ54l9WRv4W4vtj0bEeyR9EnggIk6V1CNpakQ8WjnuIWD7wX6BalWOadOmc8yMhYM9dVxbd3LOyDP3RYP7oWlZ+2I8VfRwVY7WTgQ2YMmixAcA1wErARcB76fynBLYZ4BrPkw+o6x7qPxeUHm9kGf26zTgnwN8xmLVqhwbb7p5nHzrePzPtPQOn7EQ90VyXyT3Q9Oy9sVd+3cNX2PG2HAE+vG4lGMuWR2j6nbgQoCI+F3Z1l35aRX4qq7imbUcl0ZXuYaZmXWA8fJPrg0kzSYTgK9P3lZdT9LLAEXEr8szx4ZPkTNI3wicDtxYzY1aFxF3SJoqaYPKpJzHyaALcBfwYHl9CzmSBEDSBsAaEXHHcHxRMzMbeeMlON4XEa9vtUPSZbX3LwBOBQ6OiPmSDgI+QCYVv6zFJRoOB06S1B0RCyLiD5Q1kmU5CeX14ZXPWgE4qZxrZmYdYlwEx74CY9m3S/ndCxwEIOm/IyLK9gXk2sSBPmMOsP9StmvB0p5jZmZjb1wEx6XVCIydYPIKy3GHcx4C+ZB9PE0aWBbui+R+aHJfDK/xOCHHzMxsmTg4mpmZ1UzI26qdxCWrmlyeqGm4+8LlisyW5JGjmZlZTccHR0mvlzRb0hxJLyrp234v6Y/l9X7luGmSZpXXK0u6aBk/dxNJJ0iaImkjSZeW3xeV3ytLmiTpKEkrl3M+Vs47ZVm/t5mZjZyOv60aEZdIuoJc1P8UWavxZWQigDuBrpIU/ITKaTsBCyTNrGy7KiIeAZC0KvAe4EXAmuQC/zMj4qctmvBs4L+Adcmk5+uX3z+NiDmSbgVOl/RZ4M3ArsBGkrYDbo2Idy9zJ5iZ2bDq+OBY7EcWGV4TWA+YCqxMJgyfQiYZfyGwlqSfAvOA3wNvIAse/wW4F/iNpDWB75OL9/8AbAF8GfhsKTt1qqQDgMPK9R8l87hOBbZr/I6IrwNExI9L8H4HGTRXAt4FHAUgabmIeHokOsXMzIZGHbTkr6Vyy/JXZMq2WWQQ3IAM/A+QOVU3IMtGHQl8DtidTP92JZmE/Gbg4oj4raQzgG9ExHWSPgTcEhGXSloO+B0Z+BZI+iBZ6eMMMm3ds4AtyZRy95ClrO4t7bkf2K2Pr/DdiPhj7TtVq3Jsf8wpZyxLF40b606Gf8wb61a0h+HuixkbrjF8FxtFvb29TJkyZeADJwD3RVNvby+77bbbjRGxw1CvMR5GjqsAHyZHbBuRKeC2I0eO15GFjb9GsyrGSuQt1guAXwLXkyWrGvlQnxsR15XXryRzrxIRT0t6GFhT0r/IgPgfwP8jR64PkcFxKjA5Ir4kaVNy5PpB4C3AxWTNx4Yz64GxfJarcrTgCgxNw90Xnbp4vKenh66urrFuRltwXzS5Kkd6BHgbefvzanIU+Dfg7vL6d8BywPuAHcjR3nHAF8iA9QPy+eST5XoLACQ9G5gXEf8s71cANiSD4LvIoPoz4Htk4J1FJiCfRY5KiYi/RsR3ynVXAP4aEV0R0UXmc914GPvBzMyGScf/MzwiQtItwKtpPvebRgbEV5XDjgHmkMHyUuBAMoAuiog/SVoNaFTHfFDS9sARwBcBJK0InELeAg1JfwT+DLydnAi0FTCTfLY5E9hG0mER8YVyzUY/7yKpp7xejVJGy8zM2kvHB8fiBvLW5pkR8bsyC3VKZdQGgKT9SvmpT5ITeP6v7NqI5m3X95O3NK8AZks6mby92pikQ0RcLmmT8noPSedGxL6Vzzm3ERglfQzYFHhxRKw3/F/dzMyGW8cHxzLKOwR4DXC0pOcAK+YuvbW8/nJEfK9y2qHAR4F9JO0B3BURT8Li6hu7Vq7/VeCoiFg4iLZsDHyLvNWLpBeTgXEH4ARJ7yeXmywq7ZoMfL1a8srMzMZexwdHci3jPhExl7zNCWRkJGfjLp4AExEzy+9Plk3XUkaDfYmIO/vYfhdwdHm9b/n9d+AVlcOuB26KiKfIdZONdq1I3tJdwABclaPJVQea3BdmI6vjg2NEPNbH9iBnqo6Z0oanWmx7svUZZmbWDsbDbFUzM7Nh1fEjx/HOVTmaXJWjyX2ROq0fXP2kc3jkaGZmVuOR4zKQdAg58/Vhcm1lI2Ud5LrJA4ADI+KkcvwkMunAJGDfiHAyNDOzNuSR47L7SMl48xHghEoGHCLiX0BIOrDMUj2RzKDzeeC7ktYdmyabmVl/PHJcdsdLei9l5Cipu2zvBYiIz0qaTgbF6cBc4DnAQuA7kj4eEVePdqPNzKxvDo7L7iMRMatk5ZnaWNAv6RJJW5AlsW4jK4LcSyYE2ImsuvE4mXPVzMzaiIPjyFoFeCmZnm4GWbVjNWAtsiAzjVuwVbWSVRwzY8DkPBPCupNzdqK5Lxo6rR+Go1pEX3p7e0f0+p2kt7d34IMG4OC4bFYCPt7XbdWIuFnSVGBb4L3AycCZZNHjZwPHt7qoS1a15pJVTe6L1Gn9MJJZjVyyqmk4/pHQOf+rak+bAu+KiKtb3VatHftVcqbqquX9J4AzJb0mIp4epfaamdkgeLbqEElaGdgDaBQrXkBJFVdmpjZsT+Zb/SqZB/ZI4JqSh3UPB0Yzs/bjkePQrQ3cGhEPA0TEpQCS3k4WX+6RtAs5ujyNLLC8qPwcIemjwIqSvhYRZ4/FFzAzs9YcHIcoIu6VtE+L7acDp8Pi0eXlpTLIFWXbCuSIfeFgRo2uytHkShRN7ovkfrCR4uC4DCLiiQH2z2+xbcAyVWZmNrb8zNHMzKzGI8c256ocTZ1WgWEkuS+S+6FpvPXFWFcw8cjRzMysZsKNHCW9GXgUuBx4EzCfzHkawPcbs0/LsQeRE2fOanGdU4DtytsjI+J6SS8BdomIY8sxB5CVOfpzckT8ZOjfyMzMhtuECo6SzgeeDzxBVsj4APAusuzUV4DfSzqucsr6ZFWN7sq2E8gSVQuBG8q2PYDr659XlmgsXqYh6VDg9oiYPUxfyczMRsCECY6lMsYngb2AfwK7AfeRQe5fZLq3q4Cuyjnd5MjxO7VrrUTmTV29bPpDH5+5HPBCMr/q/5Aj1CckzQdOBf4aEb8anm9oZmbDZcIER2Ad8jbok8De5Mhxatm3K/A7AEl7kaPJp1ly5DgJ+FFEnBIRT0paH3hWOX++pDPJYLmWpC7gLOAC4DAyM86BZLLxO8l+3xw4Cpg5It/WzMyGbMIEx4i4TdJq5OjxfjIR+AfL7vOAiyQ9G1gP+EIpQ9VNGTlK2hY4qHLJNchk4wB/j4iuFs8cp1SOP7ucMw8QmU6uJVflaK3TKjCMJPdFcj80jbe+WJbk4a7KsRQk7Q28mayK8V3yturaABERkr5JPjtcNMhL7gWsWF7fBvxpgOMP4Jkjx5ZclaO1TqvAMJLcF8n90DTe+mJZMh8NR1WOCbOUIyLOAz4DrAtsBWzQ2CdpX+D/gL+2OlfSqsBkckZrwxOlFuMHyPJT/bmWnBm7CfAqYEfg5qX/FmZmNhrGzz8zBu8VwBZkkPwZQEScC5wLIOkN5GzUqneRzyVPqmz7T0k9ZPHiC/v5vFeRt2rr/gvYbOmbb2ZmI20iBscvRMSXynrHZ4iIZwS6iPgMOeqsuj4iZkragSxe3JefRUTLz5I0a5BtNjOzUTTRguOvKOsRG8szJPW55rDV4v+KfcsxN9Bc73g98NvK+b3kc86+rj9zcM02M7PRNKGCYykR9XRt2zMqZwzyWq0qbiyiFDweLi5Z1eTyRE3ui+R+aHJfDK8JMyHHzMxssBwczczMahwczczMahwczczMakY9OEp6vaTZkuZIepGkHkm/l/TH8nq/fs6dKul9ktZZxjYcUnKoLs05G0n6rqQVyvv3SbqubFPZNlnSj0ticiStIOkcSRstS3vNzGx0jXpwjIhLgNcBF5MzO48lF+D/EPgW0CVprcbxktaVtG55+zbgDDKJd2P/OyUtsZhe0uqSlq+836AE5Nll6cYRwDur2yRtQP8+DxwREQtKxpw3RMRLgAfJjDcAxwCfiYgny3ddUD7rc4PuIDMzG3NjtZRjPzIYrklmj5kKrEzmOp1CyVlaKl9cA6xYKl38Hughayo2PA+4EfhLZVs3mRT8GICIuE/SNWQmm23JLDmzgZ+TpaTuioj7+mqspK2ARyvHrAY8Ul7/DZgqaQYwLSJ6qudGxL2SHpe0RUQMlH/VzMzawKgHR0krA+8BFgCzyHqHG5S2bAxcGBEPSFob+DHwEaAXuBTYMyJ2qF2ylwxWVacCV0h6QUTcVLZ9mRx53k3mSX0JcDuwoIxm+7MjcGXjTWnfmpLeAuxPlp06HXhrH+dfWa4xqOBYrcoxffr0YUmiOx709va6Lwr3RXI/NLkvmjq1KscqwIfJ0eJGwGVkncWVgevI+okbAZcDJ0fEOQCS/gHMkvSBiLiocr17gQ2rH1CqbBwHHA3sI2kS8JryOXPJ0ePPgQ8BT5bbsh9t3A5tYW1yhFi1FznqPISs5nEx8OVS9uonEXFc5diHgO0H7Jlm+xdX5dhyyy2jq6trsKeOaz09PbgvkvsiuR+a3BdNnVqV4xFyBLcFcDVZneJv5IjuZrLocC9wZER8o3FSRPwaeCVwqKRvSppadt1Ejj6RtHdje0RcDUyXtAr5PQPYp3zmj4BbgG+SpaQuof/MNg/TrN3YaM+DEfFlsjbkLsB9wJ/Kc8j/lrRG5fBpwD8H0zlmZjb2Rn3kWEZ1twCvJkeP25HBYzmyggVkYHzGrc6ImCNpZ/JW5ryy+VrgREmbAEeRga9x/CsBJB1ABsHusmtD8rbug8D7y7azy08rVwGHA+e02HciOULdlBz9Qgbjal3ILuDkPq5tZmZtZqwm5NxATso5MyJ+J2kmMKWRDLw/ERHAdyrvn5J0JPAD4GN95DxdIvBJOgR4OCIuGExjI+KOsoxkg+rEHUm7AHdHxO2S7gQOlnQzeVv13+WYDYA1IuKOwXyWmZmNvbGYkLM9+ZzuNcDRkp5Dzk6VpLeW11+OiO8N9poRcRVL8UxviA4HTpLUXZZzTAbeRz5vJCIWkhNzFitrIk8q55qZWYcYi5HjncA+ETEXeHtjY1lIr1LZYkRFxGlDOGcOeTu38X4eGeD7O2dB9RwzM+sMY/HM8bE+tgc5acbMzGxMObeqmZlZjYOjmZlZjYOjmZlZTccER0ndkrpr214t6RJJF0vqKlU9eiQ9WHm9Y4truSqHmZn1aazWOQ6KpEfITDbVbd3l5VZkAoF9gVMiokfS18mEAquTeVuJiKvKWsPqAv/nAHeX9Y4NB/SXfJysynFYvSqHpM+TeVN7aFGVQ9IR5dy9l/Lrm5nZGGnr4Aj8kixP9V7g6+RI9z1k4NsH2JlM0P1sSVfRnO26EWXNoaR/R8Q3XJXDzMwGq92D47eBD5BJyL9AJgg4jRw1/jYizi65U18bEbuXKhnVCh2rVvKzdkxVDjMzG1vK5YXtS9KewBuAdwNPAp8l85Z+CngA+BIZ6GYBmwGbVE5fNSJeVKpy7A/sTtaHfCs5atywXPM++qnKIelDwA0RcXll2zrkqPNa4MXA08BOwDOqcpR8sNtHxKcH+Z2rJau2P++88wZz2rjX29vLlClTxroZbcF9kdwPTe6Lpt7eXnbbbbcbW5Q4HLS2HTlKei7wCbLixl2UZ4jFKmQu1dPJMlcrAReRScTPqhy3T/ldrcrxAvK55F/IEellwMsYQlUOskTVemRVjjPIqhz7SJotaY1KwoOlqsrhklWtuSRPk/siuR+a3BdNw1Gyqm2DI/ks7y3A+RGxS3WHpMuAXYH/BG4DdiwJzKFZeQNg1fJ7P1yVw8zMBqltg2NEPAEgCUk9td2LSrq5X0uq3kf4FDkz9I3kqPJGSZNclcPMzJZG2wbHqojoqr4vI0dq214AnAocHBHzJR1ETubZmbx1uqxclcPMbIJo++BYv6Va3xYRvcBBAJL+u4woGxUxWk6AcVUOMzPrT8dkyBmMRmA0MzNbFuMqOJqZmQ0HB0czM7MaB0czM7OaCRMcJe0saY6kX0i6SdLtkjaWtHz5mVSO+2lZxD9b0m2N6h2SdpJ0fHk9RdLM8rND5TNmDdCGYyV1jdiXNDOzYdH2s1WHS0RcLuki4HiymsdryFRyt5IL9jcDto6IxTNQ6yWyKjYis+KcBhwt6e9kQoJtK2syX19m0tadIunR8ro3Il6/DF/LzMxGwIQJjhU/BKYAXyETBVwM/Bk4HxYHxDeXY9cHPtbHdR6IiJtLVp5GurevAu8o+1cCWgXH99Yrd5iZWXuZiMFxT3LkuAnwazK129pkeSzK+wMj4u6S33VBH9fpLrdIHyATjkPme/0icANwKfDPcszpwJxyzMskfQR4FvB2B0ozs/YzEYNjdeR4DfAhssbjF8v+rYEzJTXWTM4GTmhxnbMi4lhJ55I5Wlcs2+cDjwP3V479akScUj1Z0nv7amCtKsewJNEdD3p7e90XhfsiuR+a3BdNvb2tbtotnYkYHBePHCPiCUm/Bl4VEbcq75HeHRF7A0jaHDhyENcUGVSvAB4lq3g8UfYF8E5JM2vnbEDWl3wGV+VozVUHmtwXyf3Q5L5oGu9VOYaVpI3IyhnHA8+hPGMkg1hIWqUkO9+7ctpawGO0Vr2t+sNy3teAvwM3R8TD5bjbydyqfyPLVv0ncDVZPut+zMys7UyYpRzAmsD3yRqRJwFI2pUc8R0DXCBp9do52wD3trjWQuBLEdEVEfuWtHUHk7dX644nJ+a8gExMviJZbPkS4NuSVm1xjpmZjaEJM3KMiFvJZRtI2hp4LrkcY/+ImCtpDWBH4GJJpwE7kIFs9xbXuhP4bG3bY5JuJGs6fql8zurAgxFxpaT/AF5Fzo6dGRFzJB0HrA7MHYnvbGZmQzNhgmNVRFwGXFZqPS4q275f2X9Ii3Nmk5Nz+rvu9rX3jwMfLq//TC4ZATi3bPvxMnwNMzMbIRPptuozNAKjmZlZ1YQOjmZmZq1MyNuqnWTegqfZ5OhLx7oZbeHwGQvpdl8Ag+uLu0543Si1xmz88cjRzMysxsFxGEl6oaTnjHU7zMxs2Tg4DpGkPSulrWZLWplMBDC9cszykvaTtJekN1e2zxqDJpuZ2SD5meMQRcQPycw4SDqL7MsXAttJml8O+yDwcuA2YENJjaUgz6u8PiIibhq1hpuZ2YAcHIfPqsCaEfEiSW8h09LdTq6NPBT4ekQcDTlyjIiZY9ZSMzPrl4PjEElaC7iOzKW6DXALsIWkdcjCyT8EZpAlsL5ZzvkJMBlYrRRFfiwi9mhx7cVVOaZNm84xMxaO9NfpCOtOzlmaNri+mAgVGlyJosl90eSqHGNrEnBtRHRLWoUscnwg8E5ge+BTETEfOFTSFsByZH//KSKu7e/C1aocG2+6eZx8q/8zQQYD90UaTF/ctX/X6DRmDLkSRZP7oslVOdrH8mSVj3uAdwN3RMR8Sd1AdzlmMrAVMF/SH8lgCXBCRHjxnplZG/Fs1aELYJXyekdgX7I//wVsLWm1iDirbJ9Flqt6PnABcCJZCuvTDoxmZu3HI8ehewyYJOlq4BHgM2RC8TPIIHl5eca4GfBr4Ldk7cczyLJZvwN+MgbtNjOzATg4DlFELAT2aryXdBT5nPG35f0TZIHjacBHgbXJNZBXkGWwDgJ+LunQiLhtlJtvZmb9cHAcJhFxYu39zwEk3Q/sExHzaqecIemsiFjQ33Unr7AcdzhHJpAP2SfCJJPBcF+YjSwHxxFWZqz2ta/fwGhmZmPDE3LMzMxqHBzNzMxqHBzNzMxqHBzNzMxqHBzNzMxqHBzNzMxqHBzNzMxqHBzNzMxqFBFj3Qbrh6R/A3eMdTvaxDTg4bFuRJtwXyT3Q5P7omkasGpETB/qBZwhp/3dERE7jHUj2oGkG9wXyX2R3A9N7oum0hebLMs1fFvVzMysxsHRzMysxsGx/X1trBvQRtwXTe6L5H5ocl80LXNfeEKOmZlZjUeOZmZmNQ6OZmZmNQ6OY0jS3pKul3SjpJNb7H9P2X+zpA9Utr9C0q/Kvm9LWnF0Wz78lqEvji3besrPwaPb8uE1iH44SNKPJV1T2/58SVdJuk7SxZLWHL1Wj4xl6ItuSbdX/jdxzOi1emQMoi/eXf7b/0rSVyRNKtsn4t+Kvvpi6f5WRIR/xuAHeDa5uH8NQMD3gTdW9r8U+BWwYvn5JbADMAW4C9ioHPcZ4PCx/j5j0Rdl37eALcb6O4xGP5RjXg08D7iusk3AH4Htyvt3AqeO9fcZi74o248Ddh7r7zBafQE8F7gcWK68Px/YfYL+rWjZF+X1Uv2t8Mhx7OwC/CAiHov8L3c6MLOy//XANyPiqYh4CjgT2IMMFNdGxD3luNNq53WiofYFwMbA+8qo6duSpo1mw4fZQP1ARFwBPF47bwvgkYi4ubz/OvC6kW3qiBtqXwBsAuxbRgcXSnrOSDd2hPXbFxFxGxkAni6blgfmMQH/VvTTF7CUfyscHMfO2sADlff3A+sMYv9A53WiofYFwG+Ar0TEjsBs4NQRbOdIG+p/2yXOK/+A6PTsV8vyv/M/AGdHRBfwBeC7w9u0UTdgX0TEfElTJZ0D3Fz+4TAR/1b01RewlH8rOv3/QJ3sH0D1X7TrlW3V/eu02N/X9k421L4gIo6sbD8f6OTnSwP1Q3/nLe4fSSsBTw1v00bdUPuCiDix8rpH0iaSVEYanWjAvpC0LXAycExE/Lpy3kT7W9FXXyz13wqPHMfOj4E3SFqtvH8rcFFl/0XAAZJWkLQc8BbgR8A1wIslrV+OO7B2XicaUl8ofULSGuW4XYHfjlqrh99A/dBSRPwFmFL+KAD8L/CTkWniqBlSXwBIOkrSs8rrHYA5HRwYYYC+kDQdOAXYuxoMmIB/K/rqi6H8rfDIcYxExP2SPgX8QtJTwNUR8QNJPcC+EXGDpB8B1wMLgXMj4gYASe8ALpH0JHAn8PGx+RbDYxn74vfAlZJ6gceAt43Nt1h2g+iHB/o5vRs4Q9Ii4J/kPyA61jL2xW+AH5T/fzxF/mOhYw3UF8Be5GjqIkmN086JiK9NtL8V9N8XS/W3whlyzMzManxb1czMrMbB0czMrMbB0czMrMbB0czMrMbB0czMrMbB0czMrMbB0czMrOb/Ay0P4sQeKj6UAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.barh(list(df.columns[:-1])[::-1], model.feature_importances_[::-1])\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}